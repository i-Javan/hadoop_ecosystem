<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
<!--    <parent>-->
<!--        <artifactId>hadoop_ecosystem</artifactId>-->
<!--        <groupId>com.github.i-javan</groupId>-->
<!--        <version>1.0</version>-->
<!--    </parent>-->
    <groupId>com.github.i-javan</groupId>
    <modelVersion>4.0.0</modelVersion>
    <version>1.0</version>
    <artifactId>i-HDFS</artifactId>


    <!-- 继承说明：这里继承SpringBoot提供的父工程 -->
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.1.3.RELEASE</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <java.version>1.8</java.version>
    </properties>

    <dependencies>
        <!-- 引入Sonatype官方的一个通用配置oss-parent -->
        <!-- <dependency> <groupId>org.sonatype.oss</groupId> <artifactId>oss-parent</artifactId>
            <version>7</version> </dependency> -->
        <!-- 添加Test依赖 -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <!-- 添加WEB依赖 -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <!-- 添加lombox依赖 -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>

        <!--添加MySQL驱动依赖 -->
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <scope>runtime</scope>
        </dependency>

        <!-- 引入第三方数据源 -->
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>druid</artifactId>
            <version>1.1.6</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <!--排除这个slf4j-log4j12-->
            <exclusions>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-log4j12</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>3.2.3</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-core</artifactId>
            <version>2.8.5</version>
        </dependency>
        <dependency>
            <groupId>cn.bestwu</groupId>
            <artifactId>ik-analyzers</artifactId>
            <version>5.1.0</version>
        </dependency>
    </dependencies>

    <!--    &lt;!&ndash; 使用阿里云镜像 &ndash;&gt;-->
    <!--    <repositories>-->
    <!--        <repository>-->
    <!--            <id>central</id>-->
    <!--            <name>aliyun maven</name>-->
    <!--            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>-->
    <!--            <layout>default</layout>-->
    <!--            &lt;!&ndash; 是否开启发布版构件下载 &ndash;&gt;-->
    <!--            <releases>-->
    <!--                <enabled>true</enabled>-->
    <!--            </releases>-->
    <!--            &lt;!&ndash; 是否开启快照版构件下载 &ndash;&gt;-->
    <!--            <snapshots>-->
    <!--                <enabled>false</enabled>-->
    <!--            </snapshots>-->
    <!--        </repository>-->
    <!--    </repositories>-->
</project>

        <!--hadoop-mapreduce-example：-->
        <!--        aggregatewordcount 计算输入文件中文字个数的基于聚合的MapReduce程序；-->
        <!--        aggregatewordlist  生成输入文件中文字个数的统计图的基于聚合的MapReduce程序；-->
        <!--        grep 计算输入文件中匹配正则表达式的文字个数的MapReduce程序；-->
        <!--        join 合并排序的平均分割的数据库的作业；-->
        <!--        pentomino 解决五格拼板问题的分块分层的MapReduce程序；-->
        <!--        pi 使用蒙地卡罗法计算pi的MapReduce程序；-->
        <!--        Randomtextwriter 在一个节点上写10G随机文本的MapReduce程序；-->
        <!--        randomwriter 在每个节点上写10G随机数据的MapReduce程序；-->
        <!--        sleep 在每个Map和Reduce作业中休憩的程序；-->
        <!--        sort 排序随机写入器生成的数据的MapReduce程序；-->
        <!--        sudoku 一个九宫格游戏的解决方案；-->
        <!--        wordcount 在输入文件中统计文字个的统计器。-->

        <!--Hadoop:-->
        <!--    离线处理：MapReduce(Distributed Computation): MapReduce是一种并行编程模型，用于编程普通硬件的设计，谷歌对大量数据的高效处理（-->
        <!--        多TB数据集）的分布式应用在大型集群（数千个节点）以及可靠的容错方式。MapReduce程序可在Apache的开源Hadoop上运行。-->
        <!--    文件系统：Hadoop Hdfs:Hadoop分布式系统是基于谷歌文件系统（GFS），并提供了一个设计在普通硬件上运行的分布式系统。它与现有的分布式-->
        <!--        文件系统有许多相似之处。来自其他分布式文件系统的差别是显著。他高度容错并设计成部署在低成本的硬件。提供了高吞吐量的-->
        <!--        应用数据访问，并且适用于具有大数据集的应用程序。-->
        <!--    实用工具：Hadoop Common Utilities：这是java库和其他Hadoop组件所需的实用工具。-->
        <!--    资源管理：Hadoop YARN Framework:作业调度和集群资源管理的框架。-->

        <!--Hadoop如何工作？-->
        <!--    建立重配置，处理大规模处理服务器这是相当昂贵的，但是作为替代，可以联系许多普通电脑采用单CPU在一起，作为一个单一功能的-->
        <!--    分布式系统，实际上，集群机可以平行读取数据集，并提供一个高得多的吞吐量。此外，这样便宜不到一个高端服务器价格。因此使用-->
        <!--    Hadoop跨越集群和低成本的机器上运行是一个不错不选择。-->

        <!--Hadoop运行整个计算机集群代码。这个过程包括以下核心任务由 Hadoop 执行：-->
        <!--        数据最初分为目录和文件。文件分为128M和64M（128M最好）统一大小块。-->
        <!--        然后这些文件被分布在不同的群集节点，以便进一步处理。-->
        <!--        HDFS，本地文件系统的顶端﹑监管处理。-->
        <!--        块复制处理硬件故障。-->
        <!--        检查代码已成功执行。-->
        <!--        执行发生映射之间，减少阶段的排序。-->
        <!--        发送排序的数据到某一计算机。-->
        <!--        为每个作业编写的调试日志。-->

        <!--HDFS有两种节点类型：NameNode和DataNode，以master/slaver模式运行。-->
        <!--    NameNode：-->
        <!--        管理文件系统的命名空间。维护整个文件系统树和这个树内的所有文件和索引目录（所有信息以两种方式持久化保存在本地磁盘：命名-->
        <!--        空间镜像和编辑日志）。如果丢失NameNode，整个文件系统将无法使用，因为无法知道如果通过数据节点重建文件。NameNode记录着每-->
        <!--        个文件中各个块所在数据节点的位置信息，但不会持久化存储这些信息，因为这些信息在DataNode启动的时候会从DataNode中重建。-->
        <!--    DataNode：-->
        <!--        保存Block（即：负责把HDFS数据库写在本地文件系统），每个Block对应一个NameNode信息文件；启动DataNode时，会向NameNode-->
        <!--        汇报Block信息；定期发送心跳给NameNode，实现通信。-->
        <!--    SecondNameNode：-->
        <!--        监控HDFS状态的辅助后台程序。类似于NameNode，每个集群都有一个SecondNameNode，且单独部署在一个单独的服务器-->
        <!--        上。与同于NameNode的时，SecondNameNode不接受/记录任何实时数据变化。但是会周期性的将EditsLog文件中记录对HDFS的操作合-->
        <!--        并到一个FsImage文件，然后清空EditsLog文件。当NameNode重启时就会加载该FsImage文件。-->
        <!--    SecondNameNode的作用：-->
        <!--        （1）如果没有SecondNameNode，NameNode的每次启动则会花费太长的时间。周期性的合并能减少重启时花费的时间。-->
        <!--        （2）可以将应为NameNode宕机而造成的数据丢失的风险尽可能降低（因为SecondNodeName合并是周期性的，所以难免会丢失一些最新-->
        <!--        的数据信息）。-->

        <!--        JobTracker 对应于 NameNode-->
        <!--        TaskTracker 对应于 DataNode-->
        <!--        NameNode和DataNode是只对数据存放而言的-->
        <!--        JobTracker和TaskTracker是对应于MapReduce执行而言-->

        <!--一、MapReduce的容错性：-->
        <!--        1， map或reduce运行时因代码原因而抛出的异常。在这种情况下，子进程JVM会在进程退出前向TaskTracker父进程发送错误报告。在-->
        <!--        日志中记录该错误。-->
        <!--        2， TaskTracker失败：有TaskTracker运行缓慢或崩溃而导致无法向JobTracker发送心跳，JobTracker会将该TaskTracker从任务调-->
        <!--        度池中移除，并重新调度该任务。-->
        <!--        3， JobTracker失败：这种失败发生的概率很小；但一旦发生导致的后果最为严重，因此通过Zookeeper协调机制来降低这种问题发生的-->
        <!--        概率。-->

        <!--二、HDFS的容错性-->
        <!--        NameNode容错性：-->
        <!--            a) SecondeNameNode可以解决NameNode单点失败的情况。但是该方法存在以下三点问题：1)必须通过人工的方式寻找并拷贝-->
        <!--                SecondNameNode中的镜像文件，手动开启NameNode，无法自动化完成。2)NameNode失败期间，任何人无法以任何形式访问、操作-->
        <!--                HDFS中的文件。3)SecondNameNode的镜像文件保存有时间差，恢复时会存在数据丢失。-->
        <!--            b)通过Zookeeper实现NameNode备份。在HDFS系统中配置多个NameNode，并向Zookeeper注册自己的存在。即可通过Zookeeper-->
        <!--                的Watch和Dispatch实现各NameNode之间的协同。-->
        <!--        DataNode容错性：-->
        <!--            DataNode是以数据块作为容错单元，默认情况下，每个数据块会被备份在三分，分别存在不同的DataNode上。当一个数据块访问-->
        <!--            失效，则会从备份的DataNode中选取一个，并备份该数据块，以保证数据块的最低备份标准。-->

